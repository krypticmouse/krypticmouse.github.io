<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Class Imbalance comes in Like a Lion | Journal | Herumb Shandilya</title>
<meta name=keywords content>
<meta name=description content="In a world without class imbalance we might&rsquo;ve been heroes.
- Neural Networks
 Keeping aside the fact that I butchered one of the greatest Video Game quotes of all time class imbalance can be a tricky thing to handle especially if you are a beginner. When I first encountered class imbalance I treated it normally, I know right, and not just that I measured the accuracy to judge the performance.">
<meta name=author content="Herumb Shandilya">
<link rel=canonical href=https://journal.herumbshandilya.com/posts/class-imbalance/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://journal.herumbshandilya.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://journal.herumbshandilya.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://journal.herumbshandilya.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://journal.herumbshandilya.com/apple-touch-icon.png>
<link rel=mask-icon href=https://journal.herumbshandilya.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.2">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="Class Imbalance comes in Like a Lion">
<meta property="og:description" content="In a world without class imbalance we might&rsquo;ve been heroes.
- Neural Networks
 Keeping aside the fact that I butchered one of the greatest Video Game quotes of all time class imbalance can be a tricky thing to handle especially if you are a beginner. When I first encountered class imbalance I treated it normally, I know right, and not just that I measured the accuracy to judge the performance.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://journal.herumbshandilya.com/posts/class-imbalance/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-06-05T00:00:00+00:00">
<meta property="article:modified_time" content="2021-06-05T00:00:00+00:00"><meta property="og:site_name" content="Journal | Herumb Shandilya">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Class Imbalance comes in Like a Lion">
<meta name=twitter:description content="In a world without class imbalance we might&rsquo;ve been heroes.
- Neural Networks
 Keeping aside the fact that I butchered one of the greatest Video Game quotes of all time class imbalance can be a tricky thing to handle especially if you are a beginner. When I first encountered class imbalance I treated it normally, I know right, and not just that I measured the accuracy to judge the performance.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://journal.herumbshandilya.com/posts/"},{"@type":"ListItem","position":3,"name":"Class Imbalance comes in Like a Lion","item":"https://journal.herumbshandilya.com/posts/class-imbalance/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Class Imbalance comes in Like a Lion","name":"Class Imbalance comes in Like a Lion","description":"In a world without class imbalance we might\u0026rsquo;ve been heroes.\n- Neural Networks\n Keeping aside the fact that I butchered one of the greatest Video Game quotes of all time class imbalance can be a tricky thing to handle especially if you are a beginner. When I first encountered class imbalance I treated it normally, I know right, and not just that I measured the accuracy to judge the performance.","keywords":[],"articleBody":" In a world without class imbalance we might’ve been heroes.\n- Neural Networks\n Keeping aside the fact that I butchered one of the greatest Video Game quotes of all time class imbalance can be a tricky thing to handle especially if you are a beginner. When I first encountered class imbalance I treated it normally, I know right, and not just that I measured the accuracy to judge the performance. Needless to say, that went quite badly, and to avoid this happening to you let me help out in avoiding an embarrassing situation in front of your teacher or whoever you report to.\nClass Imbalance refers to a condition where the no. of data points corresponding to a class overpowers the other in a significant way. This could happen cause of bias towards a particular class during data collection, error during labeling, etc. I mean the cause doesn’t matter once the data is served so all you can do now is see what you can do with whatever you have.\nWe’ll see how to tackle class imbalance in different domains like structured data, NLP, and CV. We’ll see some of the techniques you can use to modify your data to balance out the class ratio and we’ll talk about how you can fix this thing on a model level without modifying the data itself.\nLoading Our Data I believe that the correct way to learn a concept is by applying what you learn in theory and that’s why I’ll be putting code for you to see how we are actually going to apply what we are talking about. For the purpose of this article I’ve decided to use the classic dataset used to teach class imbalance i.e. Credit Card Fraud Detection.\ndf = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv') X = df.drop('Class', axis = 1) Y = df['Class'] Y.value_counts() Output:-\n0 284315 1 492 Name: Class, dtype: int64 I guess it’s safe to say that our data is messed up. YAY! So now that we have our data let’s get some action.\nChoosing The Correct Metric First things first, whenever you see class imbalance you have to ditch Accuracy then and there no questions asked. Think about it you give your model data to tell if a patient is diabetic or not but the data only has 10% samples for diabetic entries, which means the model can attain 90% accuracy just by predicting not diabetic every time. What you wanna see is how well the model can classify the diabetic entries or our minority class. For this, we can use various metrics:-\n Precision: Out of all entries classified as class A how many were correctly classified. Recall: How many entries of class A was our model able to recall correctly. F1-Score: Harmonic mean of Precision and Recall. ROC-AUC Score: Area under Curve of plot between Specificity and Sensitivity Values at different thresholds. PR Curve: Plot between Precision and Recall Values at different thresholds.  MCC and Kappa Score So you get the gist right, Accuracy is not always accurate. But apart from the above-mentioned, I wanna talk about one more matrix. The Dark Horse of the Evaluation Metrics and arguably the best classification metric Matthew’s Coherent Coefficient or MCC Score if you may.\nThe above metrics are fine too but MCC Score is much more reliable since it gives a good score only when all the portions of the confusion matrix give good results i.e. TP, FP, TN, and FN.\nMCC is designed for binary classification but it can be used for multi-class classification using micro or macro averaging. We also have Kappa Score that can be used for both imbalanced and multi-class data. Note that there are many papers that argue the reliability of Kappa score and many papers that defend it. Mostly revolving around its unwanted behavior but let’s leave it a topic for another blog.\nScoring The Baseline Results Well, I hope you were able to grasp the importance of proper metrics when dealing with an imbalanced dataset. So let’s start by checking the performance of our baseline model. Now in order to score our model, we’ll have to split the data into training and testing splits but our data is imbalanced so we can’t just do random splits. We need the data to retain the original class ratio and for that, we have the stratify parameter in train_test_split itself.\nfrom sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 1, stratify = Y) Well that was easy, wasn’t it? Now let’s go ahead and train our baseline model and check its baseline metrics using classification_report and confusion_matrix.\nfrom sklearn.ensemble import RandomForestClassifier from sklearn.metrics import classification_report, confusion_matrix clf = RandomForestClassifier() clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Output:-\nConfusion Matrix:- [[71073 6] [ 17 106]] precision recall f1-score support 0 1.00 1.00 1.00 71079 1 0.95 0.86 0.90 123 accuracy 1.00 71202 macro avg 0.97 0.93 0.95 71202 weighted avg 1.00 1.00 1.00 71202 Choosing Suitable Algorithm? Now that we understand the importance of metrics in measuring the performance of a model in class imbalance, we can move on and check if there are any algorithms that aren’t really bothered by class imbalance.\nI mean on paper KNN shouldn’t be bothered with class imbalance but there is something Hellinger Distance Decision Trees, basically decision trees that use Hellinger Distance as the split criterion. They were created to tackle the effect of imbalance on decision trees.\nThere is also a way by which you can modify your algorithm to give importance to minority class prediction by the use of class weights. Let’s talk more about this cause why not.\nCost-Sensitive Algorithms Please don’t be intimidated by the name it’s a rather simple concept, basically you assign weights to each class what these signify is that how much will the algorithm be penalized for a misclassification for an entry of a class. There are many algorithms in sklearn that support class weighing and few that don’t support it.\nThe weights are assigned to the class such that the minority class has a higher weight than the majority class. We would expect that the algorithm trained on class weights will perform better as compared to the standard one.\nIn order to pass weights to the algorithm, you can simply pass the dictionary with key as class and value as the weight to the corresponding key to the class_weight parameter. Let’s try doing this in our classifier.\nfrom sklearn.ensemble import RandomForestClassifier from sklearn.metrics import classification_report, confusion_matrix clf = RandomForestClassifier(verbose = 100, class_weight = {0:600,1:1}) clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Output:-\n precision recall f1-score support 0 1.00 1.00 1.00 71079 1 0.92 0.88 0.90 123 accuracy 1.00 71202 macro avg 0.96 0.94 0.95 71202 weighted avg 1.00 1.00 1.00 71202 Recall value seems to have increased a bit that means our cost-sensitive model is able to recall more values from minority class in the testing set. You can try out different combinations to check if you can get better results.\nNow one question that may arise in your mind is, what weights should I assign to which class? There is a simple answer to this question i.e. by tuning the weights. You can select a range of values and using GridSearch to find which ones work the best.\nLet’s say you are a daredevil and wanna tune the weights then, you can try using compute_class_weight() utility in sklearn to compute class weights and use them as the weights for the algorithm. In my experience, it rarely gives the best result as compared to tuned ones. But tuning is actually pretty simple, below I’ll tell you how to do it and I want you to try it out by redefining the param_grid according to what you think is the best. You can comment on your findings if you like too 😃\nfrom sklearn.model_selection import GridSearchCV param_grid = { 'class_weight' : [{0:600,1:1}, {0:700,1:1}, {0:800,1:1}] } grid = GridSearchCV(RandomForestClassifier(), param_grid = param_grid) grid.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) In neural networks to you can train your model with assigned class weights to tackle the issue of class imbalance. The syntax is pretty similar in the sense you just pass the class weights to the network. In Tensorflow you pass weights in the fit() function and in PyTorch you pass weights in the Loss function.\n# PyTorch - Pass weight tensor in loss function pytorch_weights = torch.tensor([0.99, 0.1]) criterion = nn.NLLLoss(weight = pytorch_weights) # TensorFlow - Pass weight dictionary in fit function tf_weights = { 0 : 99, 1 : 1 } model.fit(x_train, y_train, batch_size = 50, class_weight = tf_weights) Handling Class Imbalance with Data Modification No no I’m not talking about modifying the values of the entries but I’m talking about how we can remove or add entries corresponding to a class to the existing data in order to balance the class ratio. There are quite a few ways to go about it and we’ll explore almost all of them in-depth. Once you have balanced out the classes it basically you good old classification problem. The ones that we’ll learn about are:-\n Undersampling - Fix for the Lazy Oversampling - Jugaad SMOTE - Fix from Logic ADASYN - SMOTE’s Sibling  It’ll be better If you install imblearn library since that’s what we’ll be using to implement the above. You can install it via the following command:-\npip install imblearn Undersampling - Fix for the Lazy Random Undersampling is a way to balance class by removing entries from the majority class randomly. I know right makes no sense, you are basically randomly deleting entries from the majority class. Not many people are fond of this mainly cuz it leads to loss of information, I too think it’s stupid to lose that precious labeled data.\nfrom imblearn.under_sampling import RandomUnderSampler us = RandomUnderSampler() x_train, y_train = us.fit_resample(x_train, y_train) clf = RandomForestClassifier() clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Output:-\nConfusion Matrix:- [[68666 2413] [ 8 115]] precision recall f1-score support 0 1.00 0.97 0.98 71079 1 0.05 0.93 0.09 123 accuracy 0.97 71202 macro avg 0.52 0.95 0.53 71202 weighted avg 1.00 0.97 0.98 71202 But, what if we undersample our data smartly? There are ways and algorithms that can be used to removed redundant data and reduce the issue of losing important information. Not just but sometimes a combination of both oversampling and undersampling can achieve good results too. But enough with that let’s learn about those smart undersampling methods.\nNear Miss Undersampling This type of undersampling basically determines the samples from the majority class that should be retained based on the distance between that sample and minority class samples. It has 3 variations to it:-\n Version - 1: Keeps the ones that have the minimum average distance from the nearest three minority class samples. Version - 2: Keeps the ones that have the minimum average distance from the farthest three minority class samples. Version - 3: Keeps the ones that have the minimum average distance from all minority class samples.  from imblearn.under_sampling import NearMiss nm_us = NearMiss(version = 3) x_train, y_train = nm_us.fit_resample(x_train, y_train) clf = RandomForestClassifier() clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Output:-\nConfusion Matrix:- [[68681 2398] [ 8 115]] precision recall f1-score support 0 1.00 0.97 0.98 71079 1 0.05 0.93 0.09 123 accuracy 0.97 71202 macro avg 0.52 0.95 0.54 71202 weighted avg 1.00 0.97 0.98 71202 I’ve tried quite a few examples and in most case version 3 really works better as compared to the other 2.\nTomek Links Undersampling This type of undersampling has a simple yet neat approach it focuses on removing the majority sample of the Tomek link. Tomek link is defined as the points that are closest to each other and both belonging to different classes, kinda like Romeo and Juliet except here only one of them dies, an apology to all R\u0026J fans. Anyways let’s try our hand on Tomek links.\nfrom imblearn.under_sampling import TomekLinks tomek_us = TomekLinks() x_train, y_train = tomek_us.fit_resample(x_train, y_train) clf = RandomForestClassifier(verbose = 100) clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Here since only Tomek links are deleted the class balance isn’t completely achieved rather only ambiguous points are removed.\nRandom Oversampling - Jugaad This is the exact opposite of what we did in undersampling instead of removing points from the majority class we explode the minority class by filling data with samples from the minority class chosen at random with repetition and hence achieving class balance. There are ways to explode minority class samples smartly and logically like by generating synthetic data but we’ll talk about them shortly.\nfrom imblearn.over_sampling import RandomOverSampler os = RandomOverSampler() x_train, y_train = os.fit_resample(x_train, y_train) clf = RandomForestClassifier(verbose = 100) clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Output:-\nConfusion Matrix:- [[71072 7] [ 17 106]] precision recall f1-score support 0 1.00 1.00 1.00 71079 1 0.94 0.86 0.90 123 accuracy 1.00 71202 macro avg 0.97 0.93 0.95 71202 weighted avg 1.00 1.00 1.00 71202 SMOTE - Fix from Logic SMOTE, or Synthetic Minority Oversampling TEchnique, is a way through which we oversample the data by generating synthetic data based on the provided samples of the minority classes. The steps required to create synthetic data are actually quite simple:-\n Take samples from the minority class Join these samples via lines Pick points that lie on these lines at random until you achieve class balance  Take the above picture, which took me 30 mins to make, as an example, we only have 4 red points in the minority sample but if we join those points and add points that lie on the red line to the existing dataset then we can balance the class ratio. This basically how SMOTE works. Simple right!\nfrom imblearn.over_sampling import SMOTE smote = SMOTE() x_train, y_train = smote.fit_resample(x_train, y_train) clf = RandomForestClassifier(verbose = 100) clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Output:-\nConfusion Matrix:- [[71066 13] [ 14 109]] precision recall f1-score support 0 1.00 1.00 1.00 71079 1 0.89 0.89 0.89 123 accuracy 1.00 71202 macro avg 0.95 0.94 0.94 71202 weighted avg 1.00 1.00 1.00 71202 Hmm, that seems fine recall went up a bit but precision took a hit. There are other variates to SMOTE that you can explore and learn about too. But for now, it’s time to move on to the next method.\nADASYN - SMOTE’s Sibling ADASYN, or Adaptive Synthetic, is a way through which we oversample the data by generating synthetic data based on the density of majority neighbors around a minority sample. The difference between SMOTE and ADASYN is that in ADASYN the no. of samples generated around a point depends on the density distribution r_x of that point whereas in SMOTE all minority samples have equal weights.\nFor example in the above image purple point will have more samples generated around it rather than the green arrow one. Let’s understand the steps required in ADASYN:-\n  Calculate the no. of points to be generated, denoted by G. Here beta is the balance factor which if kept 1 generates a point to achieve perfect class balance. $$ G = ( n_M - n_m) * {\\beta} $$ where n_M  For all i that belong to minority class we find the ratio:- $$ r_i = Δ_i / K $$ where K is the no. of neighbors and Δ represents the no. of samples belonging to the majority class out of those K neighbors.\n  Convert the above to probability distribution. $$ \\hat{r_i} = r_i / \\sum{r_i} $$\n  Calculate the no. of data points to be generated around each minority sample. Then for each minority sample, you generate gᵢ no. of samples. $$ g_i = \\hat{r_i} * G $$\n  from imblearn.over_sampling import ADASYN adasyn = ADASYN() x_train, y_train = adasyn.fit_resample(x_train, y_train) clf = RandomForestClassifier(verbose = 100) clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(f'Confusion Matrix:-\\n {confusion_matrix(y_test,y_pred)}\\n') print(classification_report(y_test, y_pred)) Output:-\nConfusion Matrix:- [[71065 14] [ 14 109]] precision recall f1-score support 0 1.00 1.00 1.00 71079 1 0.89 0.89 0.89 123 accuracy 1.00 71202 macro avg 0.94 0.94 0.94 71202 weighted avg 1.00 1.00 1.00 71202 Handling Class Imbalance in Image Classification In Image Classification, the usual way to handle class imbalance is to explode the data using Oversampling or via Data Augmentation. In oversampling, it’s pretty simple you copy and you replicate like the good old way.\nIn Oversampling by Data Augmentation, you can generate samples by changing the nature of the image itself. For those who don’t know Image Augmentation refers to changing the aspects of an image like its scale, angle orientation, etc. Keep in mind I’m not talking about just applying augmentation to the image but saving those augmentations if you do the first the dataset will be still imbalanced.\nAnother way to tackle this is by passing class_weights to the CNN model. Now unless you are a person who loves pain chances are you’ll be using a CNN model or a pre-trained model for image classification for which we can define class_weights and train the network accordingly.\nHandling Class Imbalance in Text Classification Text Classification for the imbalanced set is also similar, we can use class_weights to define penalty for misclassification of each class. Chances are you might be using LSTM, BERT, etc. for which we can utilize class_weights.\nWe can also remove duplicate sentences too. Like if you have 2 sentences, “Bag is in the room” and “Bag is in room”, welp they are basically the same so we can remove one of them. Removing such duplicate messages will help you reduce the size of your majority class.\nThe next way is oversampling the google old random way i.e. Random Oversampling or you can explode minority samples with text augmentations. Wait what? Text Augmentations!? I mean in images we rotate, scale up, crop, rotate, etc. but what can we do with text? In text augmentation we start by tokenizing sentences then we can shuffle and rejoin them to generate new texts. We can also replace adjectives, verbs, etc. by its a synonym to generate text with the same meaning.\nThere is another way where you are converting English text to a language and converting back to English using language translation.\nFrom Me to You… Boy was that a lot of information to grasp. Imbalance classification can be a pain I mean in a perfect world there would be no imbalance, sadly we live in a world where 4-koma mangas rarely get an anime adaptation, so unfair. The point is where is a will there is a way and I hope I was able to guide you through that way properly. See you in the next article!\n","wordCount":"3140","inLanguage":"en","datePublished":"2021-06-05T00:00:00Z","dateModified":"2021-06-05T00:00:00Z","author":{"@type":"Person","name":"Herumb Shandilya"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://journal.herumbshandilya.com/posts/class-imbalance/"},"publisher":{"@type":"Organization","name":"Journal | Herumb Shandilya","logo":{"@type":"ImageObject","url":"https://journal.herumbshandilya.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://journal.herumbshandilya.com accesskey=h title="Herumb's Journal (Alt + H)">Herumb's Journal</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://journal.herumbshandilya.com/posts/ title=Posts>
<span>Posts</span>
</a>
</li>
<li>
<a href=https://the-ir-book.herumbshandilya.com/ title="The Small Book of Information Retrieval">
<span>The Small Book of Information Retrieval</span>
</a>
</li>
<li>
<a href=https://www.herumbshandilya.com/ title=Portfolio>
<span>Portfolio</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Class Imbalance comes in Like a Lion
</h1>
<div class=post-meta><span title="2021-06-05 00:00:00 +0000 UTC">June 5, 2021</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;Herumb Shandilya
</div>
</header>
<div class=post-content><blockquote>
<p><em>In a world without class imbalance we might&rsquo;ve been heroes.</em></p>
<p><strong>- Neural Networks</strong></p>
</blockquote>
<p>Keeping aside the fact that I butchered one of the greatest Video Game quotes of all time class imbalance can be a tricky thing to handle especially if you are a beginner. When I first encountered class imbalance I treated it normally, I know right, and not just that I measured the accuracy to judge the performance. Needless to say, that went quite badly, and to avoid this happening to you let me help out in avoiding an embarrassing situation in front of your teacher or whoever you report to.</p>
<p>Class Imbalance refers to a condition where the no. of data points corresponding to a class overpowers the other in a significant way. This could happen cause of bias towards a particular class during data collection, error during labeling, etc. I mean the cause doesn&rsquo;t matter once the data is served so all you can do now is see what you can do with whatever you have.</p>
<p>We&rsquo;ll see how to tackle class imbalance in different domains like structured data, NLP, and CV. We&rsquo;ll see some of the techniques you can use to modify your data to balance out the class ratio and we&rsquo;ll talk about how you can fix this thing on a model level without modifying the data itself.</p>
<p><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1622800140013/qGeorNIZD.png alt="i have too many books.png">
</p>
<h2 id=loading-our-data>Loading Our Data<a hidden class=anchor aria-hidden=true href=#loading-our-data>#</a></h2>
<p>I believe that the correct way to learn a concept is by applying what you learn in theory and that&rsquo;s why I&rsquo;ll be putting code for you to see how we are actually going to apply what we are talking about. For the purpose of this article I&rsquo;ve decided to use the classic dataset used to teach class imbalance i.e. <a href=https://www.kaggle.com/mlg-ulb/creditcardfraud>Credit Card Fraud Detection</a>.</p>
<pre tabindex=0><code>df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')

X = df.drop('Class', axis = 1)
Y = df['Class']

Y.value_counts()
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>0    284315
1     492
Name: Class, dtype: int64
</code></pre><p>I guess it&rsquo;s safe to say that our data is messed up. YAY! So now that we have our data let&rsquo;s get some action.</p>
<h2 id=choosing-the-correct-metric>Choosing The Correct Metric<a hidden class=anchor aria-hidden=true href=#choosing-the-correct-metric>#</a></h2>
<p>First things first, whenever you see class imbalance you have to ditch Accuracy then and there no questions asked. Think about it you give your model data to tell if a patient is diabetic or not but the data only has 10% samples for diabetic entries, which means the model can attain 90% accuracy just by predicting not diabetic every time. What you wanna see is how well the model can classify the diabetic entries or our minority class. For this, we can use various metrics:-</p>
<ul>
<li><strong>Precision:</strong> Out of all entries classified as class A how many were correctly classified.</li>
<li><strong>Recall:</strong> How many entries of class A was our model able to recall correctly.</li>
<li><strong>F1-Score:</strong> Harmonic mean of Precision and Recall.</li>
<li><strong>ROC-AUC Score:</strong> Area under Curve of plot between Specificity and Sensitivity Values at different thresholds.</li>
<li><strong>PR Curve:</strong> Plot between Precision and Recall Values at different thresholds.</li>
</ul>
<h3 id=mcc-and-kappa-score>MCC and Kappa Score<a hidden class=anchor aria-hidden=true href=#mcc-and-kappa-score>#</a></h3>
<p>So you get the gist right, <strong>Accuracy is not always accurate</strong>. But apart from the above-mentioned, I wanna talk about one more matrix. The Dark Horse of the Evaluation Metrics and arguably the best classification metric <strong>Matthew&rsquo;s Coherent Coefficient</strong> or MCC Score if you may.</p>
<p><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1622802585385/KKh1JS7cpP.png alt=1_8E2rPn_ccOqGuPYj1gBTAg.png>
</p>
<p>The above metrics are fine too but MCC Score is much more reliable since it gives a good score only when all the portions of the confusion matrix give good results i.e. TP, FP, TN, and FN.</p>
<p>MCC is designed for binary classification but it can be used for multi-class classification using micro or macro averaging. We also have Kappa Score that can be used for both imbalanced and multi-class data. Note that there are many papers that argue the reliability of Kappa score and many papers that defend it. Mostly revolving around its unwanted behavior but let&rsquo;s leave it a topic for another blog.</p>
<h3 id=scoring-the-baseline-results>Scoring The Baseline Results<a hidden class=anchor aria-hidden=true href=#scoring-the-baseline-results>#</a></h3>
<p>Well, I hope you were able to grasp the importance of proper metrics when dealing with an imbalanced dataset. So let&rsquo;s start by checking the performance of our baseline model. Now in order to score our model, we&rsquo;ll have to split the data into training and testing splits but our data is imbalanced so we can&rsquo;t just do random splits. We need the data to retain the original class ratio and for that, we have the <strong>stratify</strong> parameter in <strong>train_test_split</strong> itself.</p>
<pre tabindex=0><code>from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(X, Y, 
                                                    test_size = 0.25, 
                                                    random_state = 1, 
                                                    stratify = Y)
</code></pre><p>Well that was easy, wasn&rsquo;t it? Now let&rsquo;s go ahead and train our baseline model and check its baseline metrics using classification_report and confusion_matrix.</p>
<pre tabindex=0><code>from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

clf = RandomForestClassifier()
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>Confusion Matrix:-
 [[71073     6]
 [   17   106]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00     71079
           1       0.95      0.86      0.90       123

    accuracy                           1.00     71202
   macro avg       0.97      0.93      0.95     71202
weighted avg       1.00      1.00      1.00     71202
</code></pre><h2 id=choosing-suitable-algorithm>Choosing Suitable Algorithm?<a hidden class=anchor aria-hidden=true href=#choosing-suitable-algorithm>#</a></h2>
<p>Now that we understand the importance of metrics in measuring the performance of a model in class imbalance, we can move on and check if there are any algorithms that aren&rsquo;t really bothered by class imbalance.</p>
<p>I mean on paper KNN shouldn&rsquo;t be bothered with class imbalance but there is something <strong>Hellinger Distance Decision Trees</strong>, basically decision trees that use Hellinger Distance as the split criterion. They were created to tackle the effect of imbalance on decision trees.</p>
<p>There is also a way by which you can modify your algorithm to give importance to minority class prediction by the use of class weights. Let&rsquo;s talk more about this cause why not.</p>
<h3 id=cost-sensitive-algorithms>Cost-Sensitive Algorithms<a hidden class=anchor aria-hidden=true href=#cost-sensitive-algorithms>#</a></h3>
<p>Please don&rsquo;t be intimidated by the name it&rsquo;s a rather simple concept, basically you assign weights to each class what these signify is that how much will the algorithm be penalized for a misclassification for an entry of a class. There are many algorithms in sklearn that support class weighing and few that don&rsquo;t support it.</p>
<p>The weights are assigned to the class such that the minority class has a higher weight than the majority class. We would expect that the algorithm trained on class weights will perform better as compared to the standard one.</p>
<p>In order to pass weights to the algorithm, you can simply pass the dictionary with key as class and value as the weight to the corresponding key to the <strong>class_weight</strong> parameter. Let&rsquo;s try doing this in our classifier.</p>
<pre tabindex=0><code>from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

clf = RandomForestClassifier(verbose = 100, class_weight = {0:600,1:1})
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     71079
           1       0.92      0.88      0.90       123

    accuracy                           1.00     71202
   macro avg       0.96      0.94      0.95     71202
weighted avg       1.00      1.00      1.00     71202
</code></pre><p>Recall value seems to have increased a bit that means our cost-sensitive model is able to recall more values from minority class in the testing set. You can try out different combinations to check if you can get better results.</p>
<p>Now one question that may arise in your mind is, what weights should I assign to which class? There is a simple answer to this question i.e. by tuning the weights. You can select a range of values and using GridSearch to find which ones work the best.</p>
<p><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1622826149673/S0MuEnBme.jpeg alt=Untitled.jpg>
</p>
<p>Let&rsquo;s say you are a daredevil and wanna tune the weights then, you can try using <strong>compute_class_weight()</strong> utility in sklearn to compute class weights and use them as the weights for the algorithm. In my experience, it rarely gives the best result as compared to tuned ones. But tuning is actually pretty simple, below I&rsquo;ll tell you how to do it and I want you to try it out by redefining the param_grid according to what you think is the best. You can comment on your findings if you like too 😃</p>
<pre tabindex=0><code>from sklearn.model_selection import GridSearchCV

param_grid = {
    'class_weight' : [{0:600,1:1}, {0:700,1:1}, {0:800,1:1}]
}

grid = GridSearchCV(RandomForestClassifier(), param_grid = param_grid)
grid.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p>In neural networks to you can train your model with assigned class weights to tackle the issue of class imbalance. The syntax is pretty similar in the sense you just pass the class weights to the network. In Tensorflow you pass weights in the fit() function and in PyTorch you pass weights in the Loss function.</p>
<pre tabindex=0><code># PyTorch - Pass weight tensor in loss function
pytorch_weights = torch.tensor([0.99, 0.1])
criterion = nn.NLLLoss(weight =  pytorch_weights)

# TensorFlow - Pass weight dictionary in fit function
tf_weights = { 0 : 99, 
               1 : 1 }
model.fit(x_train, y_train, batch_size = 50, class_weight = tf_weights)
</code></pre><h2 id=handling-class-imbalance-with-data-modification>Handling Class Imbalance with Data Modification<a hidden class=anchor aria-hidden=true href=#handling-class-imbalance-with-data-modification>#</a></h2>
<p>No no I&rsquo;m not talking about modifying the values of the entries but I&rsquo;m talking about how we can remove or add entries corresponding to a class to the existing data in order to balance the class ratio. There are quite a few ways to go about it and we&rsquo;ll explore almost all of them in-depth. Once you have balanced out the classes it basically you good old classification problem. The ones that we&rsquo;ll learn about are:-</p>
<ul>
<li>Undersampling - Fix for the Lazy</li>
<li>Oversampling - Jugaad</li>
<li>SMOTE - Fix from Logic</li>
<li>ADASYN - SMOTE&rsquo;s Sibling</li>
</ul>
<p>It&rsquo;ll be better If you install <strong>imblearn</strong> library since that&rsquo;s what we&rsquo;ll be using to implement the above. You can install it via the following command:-</p>
<pre tabindex=0><code>pip install imblearn
</code></pre><h3 id=undersampling---fix-for-the-lazy>Undersampling - Fix for the Lazy<a hidden class=anchor aria-hidden=true href=#undersampling---fix-for-the-lazy>#</a></h3>
<p>Random Undersampling is a way to balance class by removing entries from the majority class randomly. I know right makes no sense, you are basically randomly deleting entries from the majority class. Not many people are fond of this mainly cuz it leads to loss of information, I too think it&rsquo;s stupid to lose that precious labeled data.</p>
<p><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1622826516604/8mEkvCM4q.png alt=raw.png>
</p>
<pre tabindex=0><code>from imblearn.under_sampling import RandomUnderSampler

us = RandomUnderSampler()
x_train, y_train = us.fit_resample(x_train, y_train)

clf = RandomForestClassifier()
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>Confusion Matrix:-
 [[68666  2413]
 [    8   115]]

              precision    recall  f1-score   support

           0       1.00      0.97      0.98     71079
           1       0.05      0.93      0.09       123

    accuracy                           0.97     71202
   macro avg       0.52      0.95      0.53     71202
weighted avg       1.00      0.97      0.98     71202
</code></pre><p>But, what if we undersample our data smartly? There are ways and algorithms that can be used to removed redundant data and reduce the issue of losing important information. Not just but sometimes a combination of both oversampling and undersampling can achieve good results too. But enough with that let&rsquo;s learn about those smart undersampling methods.</p>
<h4 id=near-miss-undersampling>Near Miss Undersampling<a hidden class=anchor aria-hidden=true href=#near-miss-undersampling>#</a></h4>
<p>This type of undersampling basically determines the samples from the majority class that should be retained based on the distance between that sample and minority class samples. It has 3 variations to it:-</p>
<ul>
<li><strong>Version - 1:</strong> Keeps the ones that have the minimum average distance from the nearest three minority class samples.</li>
<li><strong>Version - 2:</strong> Keeps the ones that have the minimum average distance from the farthest three minority class samples.</li>
<li><strong>Version - 3:</strong> Keeps the ones that have the minimum average distance from all minority class samples.</li>
</ul>
<pre tabindex=0><code>from imblearn.under_sampling import NearMiss

nm_us = NearMiss(version = 3)
x_train, y_train = nm_us.fit_resample(x_train, y_train)

clf = RandomForestClassifier()
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>Confusion Matrix:-
 [[68681  2398]
 [    8   115]]

              precision    recall  f1-score   support

           0       1.00      0.97      0.98     71079
           1       0.05      0.93      0.09       123

    accuracy                           0.97     71202
   macro avg       0.52      0.95      0.54     71202
weighted avg       1.00      0.97      0.98     71202
</code></pre><p>I&rsquo;ve tried quite a few examples and in most case version 3 really works better as compared to the other 2.</p>
<h4 id=tomek-links-undersampling>Tomek Links Undersampling<a hidden class=anchor aria-hidden=true href=#tomek-links-undersampling>#</a></h4>
<p>This type of undersampling has a simple yet neat approach it focuses on removing the majority sample of the Tomek link. Tomek link is defined as the points that are closest to each other and both belonging to different classes, kinda like Romeo and Juliet except here only one of them dies, an apology to all R&J fans. Anyways let&rsquo;s try our hand on Tomek links.</p>
<pre tabindex=0><code>from imblearn.under_sampling import TomekLinks

tomek_us = TomekLinks()
x_train, y_train = tomek_us.fit_resample(x_train, y_train)

clf = RandomForestClassifier(verbose = 100)
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p>Here since only Tomek links are deleted the class balance isn&rsquo;t completely achieved rather only ambiguous points are removed.</p>
<h3 id=random-oversampling---jugaad>Random Oversampling - Jugaad<a hidden class=anchor aria-hidden=true href=#random-oversampling---jugaad>#</a></h3>
<p>This is the exact opposite of what we did in undersampling instead of removing points from the majority class we explode the minority class by filling data with samples from the minority class chosen at random with repetition and hence achieving class balance. There are ways to explode minority class samples smartly and logically like by generating synthetic data but we&rsquo;ll talk about them shortly.</p>
<pre tabindex=0><code>from imblearn.over_sampling import RandomOverSampler

os = RandomOverSampler()
x_train, y_train = os.fit_resample(x_train, y_train)

clf = RandomForestClassifier(verbose = 100)
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>Confusion Matrix:-
 [[71072     7]
 [   17   106]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00     71079
           1       0.94      0.86      0.90       123

    accuracy                           1.00     71202
   macro avg       0.97      0.93      0.95     71202
weighted avg       1.00      1.00      1.00     71202
</code></pre><h3 id=smote---fix-from-logic>SMOTE - Fix from Logic<a hidden class=anchor aria-hidden=true href=#smote---fix-from-logic>#</a></h3>
<p>SMOTE, or Synthetic Minority Oversampling TEchnique, is a way through which we oversample the data by generating synthetic data based on the provided samples of the minority classes. The steps required to create synthetic data are actually quite simple:-</p>
<ol>
<li>Take samples from the minority class</li>
<li>Join these samples via lines</li>
<li>Pick points that lie on these lines at random until you achieve class balance</li>
</ol>
<p><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1622832428836/1jcbnOKZ3.png alt="i have too many books (2) (1).png">
</p>
<p>Take the above picture, which took me 30 mins to make, as an example, we only have 4 red points in the minority sample but if we join those points and add points that lie on the red line to the existing dataset then we can balance the class ratio. This basically how SMOTE works. Simple right!</p>
<pre tabindex=0><code>from imblearn.over_sampling import SMOTE

smote = SMOTE()
x_train, y_train = smote.fit_resample(x_train, y_train)

clf = RandomForestClassifier(verbose = 100)
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>Confusion Matrix:-
 [[71066    13]
 [   14   109]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00     71079
           1       0.89      0.89      0.89       123

    accuracy                           1.00     71202
   macro avg       0.95      0.94      0.94     71202
weighted avg       1.00      1.00      1.00     71202
</code></pre><p>Hmm, that seems fine recall went up a bit but precision took a hit. There are other variates to SMOTE that you can explore and learn about too. But for now, it&rsquo;s time to move on to the next method.</p>
<h3 id=adasyn---smotes-sibling>ADASYN - SMOTE&rsquo;s Sibling<a hidden class=anchor aria-hidden=true href=#adasyn---smotes-sibling>#</a></h3>
<p>ADASYN, or Adaptive Synthetic, is a way through which we oversample the data by generating synthetic data based on the density of majority neighbors around a minority sample. The difference between SMOTE and ADASYN is that in ADASYN the no. of samples generated around a point depends on the density distribution r_x of that point whereas in SMOTE all minority samples have equal weights.</p>
<p><img loading=lazy src=https://cdn.hashnode.com/res/hashnode/image/upload/v1622834736808/9Xo5E88eD.png alt="i have too many books (3) (1).png">
</p>
<p>For example in the above image purple point will have more samples generated around it rather than the green arrow one. Let&rsquo;s understand the steps required in ADASYN:-</p>
<ol>
<li>
<p>Calculate the no. of points to be generated, denoted by G. Here beta is the balance factor which if kept 1 generates a point to achieve perfect class balance.
$$
G = ( n_M - n_m) * {\beta}
$$
where n_M &lt;- No. of majority class samples and n_m &lt;- No. of minority class samples</p>
</li>
<li>
<p>For all i that belong to minority class we find the ratio:-
$$
r_i = Δ_i / K
$$
where K is the no. of neighbors and Δ represents the no. of samples belonging to the majority class out of those K neighbors.</p>
</li>
<li>
<p>Convert the above to probability distribution.
$$
\hat{r_i} = r_i / \sum{r_i}
$$</p>
</li>
<li>
<p>Calculate the no. of data points to be generated around each minority sample. Then for each minority sample, you generate gᵢ no. of samples.
$$
g_i = \hat{r_i} * G
$$</p>
</li>
</ol>
<pre tabindex=0><code>from imblearn.over_sampling import ADASYN

adasyn = ADASYN()
x_train, y_train = adasyn.fit_resample(x_train, y_train)

clf = RandomForestClassifier(verbose = 100)
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(f'Confusion Matrix:-\n {confusion_matrix(y_test,y_pred)}\n')
print(classification_report(y_test, y_pred))
</code></pre><p><strong>Output:-</strong></p>
<pre tabindex=0><code>Confusion Matrix:-
 [[71065    14]
 [   14   109]]

              precision    recall  f1-score   support

           0       1.00      1.00      1.00     71079
           1       0.89      0.89      0.89       123

    accuracy                           1.00     71202
   macro avg       0.94      0.94      0.94     71202
weighted avg       1.00      1.00      1.00     71202
</code></pre><h2 id=handling-class-imbalance-in-image-classification>Handling Class Imbalance in Image Classification<a hidden class=anchor aria-hidden=true href=#handling-class-imbalance-in-image-classification>#</a></h2>
<p>In Image Classification, the usual way to handle class imbalance is to explode the data using Oversampling or via Data Augmentation. In oversampling, it&rsquo;s pretty simple you copy and you replicate like the good old way.</p>
<p>In Oversampling by Data Augmentation, you can generate samples by changing the nature of the image itself. For those who don&rsquo;t know Image Augmentation refers to changing the aspects of an image like its scale, angle orientation, etc. Keep in mind I&rsquo;m not talking about just applying augmentation to the image but saving those augmentations if you do the first the dataset will be still imbalanced.</p>
<p>Another way to tackle this is by passing class_weights to the CNN model. Now unless you are a person who loves pain chances are you&rsquo;ll be using a CNN model or a pre-trained model for image classification for which we can define class_weights and train the network accordingly.</p>
<h2 id=handling-class-imbalance-in-text-classification>Handling Class Imbalance in Text Classification<a hidden class=anchor aria-hidden=true href=#handling-class-imbalance-in-text-classification>#</a></h2>
<p>Text Classification for the imbalanced set is also similar, we can use class_weights to define penalty for misclassification of each class. Chances are you might be using LSTM, BERT, etc. for which we can utilize class_weights.</p>
<p>We can also remove duplicate sentences too. Like if you have 2 sentences, &ldquo;Bag is in the room&rdquo; and &ldquo;Bag is in room&rdquo;, welp they are basically the same so we can remove one of them. Removing such duplicate messages will help you reduce the size of your majority class.</p>
<p>The next way is oversampling the google old random way i.e. Random Oversampling or you can explode minority samples with text augmentations. Wait what? Text Augmentations!? I mean in images we rotate, scale up, crop, rotate, etc. but what can we do with text? In text augmentation we start by tokenizing sentences then we can shuffle and rejoin them to generate new texts. We can also replace adjectives, verbs, etc. by its a synonym to generate text with the same meaning.</p>
<p>There is another way where you are converting English text to a language and converting back to English using language translation.</p>
<h2 id=from-me-to-you>From Me to You&mldr;<a hidden class=anchor aria-hidden=true href=#from-me-to-you>#</a></h2>
<p>Boy was that a lot of information to grasp. Imbalance classification can be a pain I mean in a perfect world there would be no imbalance, sadly we live in a world where 4-koma mangas rarely get an anime adaptation, so unfair. The point is where is a will there is a way and I hope I was able to guide you through that way properly. See you in the next article!</p>
</div>
<footer class=post-footer>
<nav class=paginav>
<a class=prev href=https://journal.herumbshandilya.com/posts/pytorch-lightning/>
<span class=title>« Prev Page</span>
<br>
<span>PyTorch Lightning: DataModules, Callbacks, TPU, and Loggers</span>
</a>
<a class=next href=https://journal.herumbshandilya.com/posts/svm-kernels/>
<span class=title>Next Page »</span>
<br>
<span>Training SVM over Custom Kernels</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Class Imbalance comes in Like a Lion on twitter" href="https://twitter.com/intent/tweet/?text=Class%20Imbalance%20comes%20in%20Like%20a%20Lion&url=https%3a%2f%2fjournal.herumbshandilya.com%2fposts%2fclass-imbalance%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Class Imbalance comes in Like a Lion on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fjournal.herumbshandilya.com%2fposts%2fclass-imbalance%2f&title=Class%20Imbalance%20comes%20in%20Like%20a%20Lion&summary=Class%20Imbalance%20comes%20in%20Like%20a%20Lion&source=https%3a%2f%2fjournal.herumbshandilya.com%2fposts%2fclass-imbalance%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Class Imbalance comes in Like a Lion on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fjournal.herumbshandilya.com%2fposts%2fclass-imbalance%2f&title=Class%20Imbalance%20comes%20in%20Like%20a%20Lion"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Class Imbalance comes in Like a Lion on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fjournal.herumbshandilya.com%2fposts%2fclass-imbalance%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Class Imbalance comes in Like a Lion on whatsapp" href="https://api.whatsapp.com/send?text=Class%20Imbalance%20comes%20in%20Like%20a%20Lion%20-%20https%3a%2f%2fjournal.herumbshandilya.com%2fposts%2fclass-imbalance%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Class Imbalance comes in Like a Lion on telegram" href="https://telegram.me/share/url?text=Class%20Imbalance%20comes%20in%20Like%20a%20Lion&url=https%3a%2f%2fjournal.herumbshandilya.com%2fposts%2fclass-imbalance%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2024 <a href=https://journal.herumbshandilya.com>Journal | Herumb Shandilya</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>
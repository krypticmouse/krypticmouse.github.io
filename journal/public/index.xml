<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Journal | Herumb Shandilya</title>
    <link>https://journal.herumbshandilya.com/</link>
    <description>Recent content on Journal | Herumb Shandilya</description>
    <generator>Hugo -- 0.154.2</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://journal.herumbshandilya.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Parallelism in CPUs: </title>
      <link>https://journal.herumbshandilya.com/posts/accelerators/</link>
      <pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/accelerators/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Youâ€™re absolutely right. I canâ€™t execute anything fast alone.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Everyone has their flaws &amp;amp; imperfections, but thatâ€™s what drives us to work together&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;To make up for those flaws. Together, we complete the job faster.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;- &lt;strong&gt;Gintoki Sakata, Gintama&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Parallelism is kinda like that too, bunch of worker doing there work in chunks and if needed accumulating the results to get the final answer. Wasn&amp;rsquo;t always like this though. Anyways, AI is everywhere these days and there are people who build AI and people who build with AI. At the heart of it both aim for the same thing, building better and &lt;strong&gt;faster&lt;/strong&gt; systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Aya Project: My Experience and Learnings</title>
      <link>https://journal.herumbshandilya.com/posts/the-aya-project-trials/</link>
      <pubDate>Mon, 20 May 2024 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/the-aya-project-trials/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;I don&amp;rsquo;t think anyone is born knowing the reason why they&amp;rsquo;re here.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It&amp;rsquo;s just something you have to find as you go along.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;-Tohru Honda, Fruits Basket&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well well, isn&amp;rsquo;t this something we&amp;rsquo;ve always wondered about? Thinking about the impact that any decision that you are taking in the present will have have in future, is it something that we can even do? Anyways, that went too philosophical but I think that&amp;rsquo;s how this blog will be too, Why? &lt;strong&gt;Aya is going to ACL LFGG&lt;/strong&gt; ðŸš€ðŸš€&lt;/p&gt;</description>
    </item>
    <item>
      <title>Writing a Compiler in Rust #1: Lexical Analysis</title>
      <link>https://journal.herumbshandilya.com/posts/rust-compiler-1/</link>
      <pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/rust-compiler-1/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Compilers are not a game of luck.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you want it to work, code hard.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;- Sora (No Game No Life)&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Another blog, another butchered quote but what matters is that they never created a season 2 for this series and I&amp;rsquo;m max pissed about it!! Anyways, as someone who has a Computer Science Degree, it&amp;rsquo;s a bit shameful for me to admit that I never formally studied compilers, well in my defense it&amp;rsquo;s because it was an elective and I chose an ML elective instead of Compiler Design. Although it is something that I&amp;rsquo;ve always enjoyed hearing a lot about.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LIMA: Less is More for Alignment</title>
      <link>https://journal.herumbshandilya.com/posts/lima/</link>
      <pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/lima/</guid>
      <description>&lt;p&gt;I can&amp;rsquo;t even being to explain how I felt reading this paper, the moment I finished it I shared it ASAP with everyone because it deserved it. Essentially, what LIMA wants to address is that big instruction dataset and RLHF aren&amp;rsquo;t necessary to produce high quality output.&lt;/p&gt;
&lt;p&gt;As I mentioned above, what LIMA wants to address is that big instruction dataset and RLHF aren&amp;rsquo;t necessary to produce high quality output. But aside from that it&amp;rsquo;s an investigation on how much examples are needed to align a model output? I&amp;rsquo;m gonna explain more soon but that&amp;rsquo;s that basic idea of the paper. Let&amp;rsquo;s just dive into it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers: Attention is all you need</title>
      <link>https://journal.herumbshandilya.com/posts/transformers/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/transformers/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Attention is Transformerâ€™s breath,&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Multi-Head is Transformerâ€™s release,&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;RNNs thou wert and art,&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;May thy model reach to greater accuracy.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;LÃ¡tom.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;- Enen No Shouboutai&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I&amp;rsquo;m getting tired of butchering anime and video game quotes so I&amp;rsquo;m thinking I should butcher some meme quotes next time. Anyways, well I have been writing on a lot of topics but something I always wanted to write about is probably explaining a research paper.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PyTorch Lightning: DataModules, Callbacks, TPU, and Loggers</title>
      <link>https://journal.herumbshandilya.com/posts/pytorch-lightning/</link>
      <pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/pytorch-lightning/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;When I was a young man,&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I had liberty but I didnâ€™t see it,&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I had time but I didnâ€™t know it,&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;And I had PyTorch Lightning but I didn&amp;rsquo;t use it.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;- Newbie PyTorch User&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Another Blog another great video game quote butchered by these hands. Anyways, when I was getting started with PyTorch one of the things that made me jealous was the fact that Tensorflow has so much support for monitoring the model performance. I mean I have to write a training loop with redundant steps while Tensorflow beginners were just passing and chilling.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Class Imbalance comes in Like a Lion</title>
      <link>https://journal.herumbshandilya.com/posts/class-imbalance/</link>
      <pubDate>Sat, 05 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/class-imbalance/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;In a world without class imbalance we might&amp;rsquo;ve been heroes.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;- Neural Networks&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Keeping aside the fact that I butchered one of the greatest Video Game quotes of all time class imbalance can be a tricky thing to handle especially if you are a beginner. When I first encountered class imbalance I treated it normally, I know right, and not just that I measured the accuracy to judge the performance. Needless to say, that went quite badly, and to avoid this happening to you let me help out in avoiding an embarrassing situation in front of your teacher or whoever you report to.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training SVM over Custom Kernels</title>
      <link>https://journal.herumbshandilya.com/posts/svm-kernels/</link>
      <pubDate>Thu, 29 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://journal.herumbshandilya.com/posts/svm-kernels/</guid>
      <description>&lt;p&gt;One thing that always intrigued me about ML is that the more you learn about it the more you realize how little you know. One such case that happened to me a few months ago when a person asked me if I could help him in SVM and me being me I was like sure not a big deal. It was a big deal.&lt;/p&gt;
&lt;p&gt;Most of us might be familiar with training models. Few of us might be familiar with when to use which model. But when it comes to the details of these models we might fail to utilize them. In SVM, most of us might use the default RBF, a few of us might play with other kernels to find a better model and chosen ones might understand the working and purpose of these kernels. But can you create a kernel of your own?&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
